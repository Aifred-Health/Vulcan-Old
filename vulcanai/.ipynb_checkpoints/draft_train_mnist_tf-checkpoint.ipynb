{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cuDNN version 7103 on context None\n",
      "Mapped name None to device cuda: GeForce GTX 960M (0000:01:00.0)\n",
      "C:\\Anaconda\\Anaconda2\\lib\\site-packages\\matplotlib\\__init__.py:1357: UserWarning:  This call to matplotlib.use() has no effect\n",
      "because the backend has already been chosen;\n",
      "matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "  warnings.warn(_use_error_msg)\n"
     ]
    }
   ],
   "source": [
    "import theano.tensor as T\n",
    "import theano\n",
    "import numpy as np\n",
    "\n",
    "from utils import get_one_hot\n",
    "from model_tests import run_test\n",
    "from vulcanai import mnist_loader\n",
    "from ops import activations, optimizers\n",
    "from sklearn.utils import shuffle\n",
    "import lasagne\n",
    "from utils import get_class\n",
    "\n",
    "from utils import get_timestamp\n",
    "import time\n",
    "import os\n",
    "\n",
    "import sys\n",
    "import json\n",
    "import cPickle as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "module compiled against API version 0xc but this version of numpy is 0xb",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;31mRuntimeError\u001b[0m: module compiled against API version 0xc but this version of numpy is 0xb"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "module compiled against API version 0xc but this version of numpy is 0xb",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;31mRuntimeError\u001b[0m: module compiled against API version 0xc but this version of numpy is 0xb"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class Network(object):\n",
    "    \"\"\"Class to generate networks and train them.\"\"\"\n",
    "\n",
    "    def __init__(self, name, dimensions, input_var, y, config,\n",
    "                 input_network=None, num_classes=None, activation='rectify',\n",
    "                 pred_activation='softmax', optimizer='adam', stopping_rule='best_validation_error',\n",
    "                 learning_rate=0.001):\n",
    "\n",
    "        \"\"\"\n",
    "        Initialize network specified.\n",
    "\n",
    "        Args:\n",
    "            name: string of network name\n",
    "            dimensions: the size of the input data matrix\n",
    "            input_var: theano tensor representing input matrix\n",
    "            y: theano tensor representing truth matrix\n",
    "            config: Network configuration (as dict)\n",
    "            input_network: None or a dictionary containing keys (network, layer).\n",
    "                network: a Network object\n",
    "                layer: an integer corresponding to the layer you want output\n",
    "            num_classes: None or int. how many classes to predict\n",
    "            activation:  activation function for hidden layers\n",
    "            pred_activation: the classifying layer activation\n",
    "            optimizer: which optimizer to use as the learning function\n",
    "            learning_rate: the initial learning rate\n",
    "        \"\"\"\n",
    "        self.name = name\n",
    "        self.layers = []\n",
    "        self.cost = None\n",
    "        self.val_cost = None\n",
    "        self.input_dimensions = dimensions\n",
    "        self.config = config\n",
    "        self.learning_rate = learning_rate\n",
    "        self.init_learning_rate = learning_rate\n",
    "        self.stopping_rule = stopping_rule\n",
    "        if not optimizers.get(optimizer, False):\n",
    "            raise ValueError(\n",
    "                'Invalid optimizer option: {}. '\n",
    "                'Please choose from:'\n",
    "                '{}'.format(optimizer, optimizers.keys()))\n",
    "        if not activations.get(activation, False) or \\\n",
    "           not activations.get(pred_activation, False):\n",
    "            raise ValueError(\n",
    "                'Invalid activation option: {} and {}. '\n",
    "                'Please choose from:'\n",
    "                '{}'.format(activation, pred_activation, activations.keys()))\n",
    "        self.activation = activation\n",
    "        self.pred_activation = pred_activation\n",
    "        self.optimizer = optimizer\n",
    "        self.input_var = input_var\n",
    "        self.y = y\n",
    "        self.input_network = input_network\n",
    "        self.input_params = None\n",
    "        \n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        \n",
    "        self.network = self.build_model(\n",
    "            config=self.config,\n",
    "            nonlinearity=activations[self.activation]\n",
    "        )\n",
    "        \n",
    "        if self.y is not None:\n",
    "            self.trainer = self.create_trainer()\n",
    "            self.validator = self.create_validator()\n",
    "\n",
    "        self.output = theano.function(\n",
    "            [i for i in [self.input_var] if i],\n",
    "            lasagne.layers.get_output(self.network, deterministic=True))\n",
    "        self.record = None\n",
    "\n",
    "        try:\n",
    "            self.timestamp\n",
    "        except AttributeError:\n",
    "            self.timestamp = get_timestamp()\n",
    "        self.minibatch_iteration = 0\n",
    "        \n",
    "    def build_model(self, config, nonlinearity):\n",
    "        \n",
    "        import jsonschema\n",
    "        import schemas\n",
    "        mode = config.get('mode')\n",
    "        if mode == 'dense':\n",
    "            jsonschema.validate(config, schemas.dense_network)\n",
    "\n",
    "            network = self.create_dense_network(\n",
    "                units=config.get('units'),\n",
    "                dropouts=config.get('dropouts'),\n",
    "                nonlinearity=nonlinearity\n",
    "            )\n",
    "        elif mode == 'conv':\n",
    "            jsonschema.validate(config, schemas.conv_network)\n",
    "\n",
    "            network = self.create_conv_network(\n",
    "                filters=config.get('filters'),\n",
    "                filter_size=config.get('filter_size'),\n",
    "                stride=config.get('stride'),\n",
    "                pool_mode=config['pool'].get('mode'),\n",
    "                pool_stride=config['pool'].get('stride'),\n",
    "                nonlinearity=nonlinearity\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError('Mode {} not supported.'.format(mode))\n",
    "            \n",
    "        \n",
    "\n",
    "        return network    \n",
    "    \n",
    "    def create_dense_network(self, units, dropouts, nonlinearity):\n",
    "        \n",
    "        if len(units) != len(dropouts):\n",
    "            raise ValueError(\n",
    "                \"Cannot build network: units and dropouts don't correspond\"\n",
    "            )\n",
    "\n",
    "        print(\"Creating {} Network...\".format(self.name))\n",
    "    \n",
    "        if self.input_network is None:\n",
    "            print('\\tInput Layer:')\n",
    "            \n",
    "            network = tf.keras.layers.InputLayer(input_shape=self.input_dimensions,\n",
    "                                                input_tensor=self.input_var,\n",
    "                                                name=\"{}_input\".format(\n",
    "                                                    self.name)).output\n",
    "            print('\\t\\t{}'.format(network.shape))\n",
    "            self.layers.append(network)\n",
    "        else:\n",
    "            network = self.input_network['network']. \\\n",
    "                layers[self.input_network['layer']]\n",
    "\n",
    "            print('Appending layer {} from {} to {}'.format(\n",
    "                self.input_network['layer'],\n",
    "                self.input_network['network'].name,\n",
    "                self.name))\n",
    "\n",
    "        if nonlinearity.__name__ == 'selu':\n",
    "            network = lasagne.layers.BatchNormLayer(\n",
    "                incoming=network,\n",
    "                name=\"{}_batchnorm\".format(self.name)\n",
    "            )\n",
    "\n",
    "        print('\\tHidden Layer:')\n",
    "        for i, (num_units, prob_dropout) in enumerate(zip(units, dropouts)):\n",
    "            if nonlinearity.__name__ == 'selu':\n",
    "                weights = tf.Variable(\n",
    "                    tf.truncated_normal([network.output_shape[1], num_units],\n",
    "                                        stddev=np.sqrt(1.0 / num_units)),\n",
    "                    name = 'weights')\n",
    "                w = lasagne.init.Normal(std=np.sqrt(1.0 / num_units))\n",
    "                b = lasagne.init.Normal(std=0.0)\n",
    "            else:\n",
    "                \n",
    "                                          \n",
    "                biases = tf.constant(0.)\n",
    "                w = lasagne.init.GlorotUniform()\n",
    "                b = lasagne.init.Constant(0.)\n",
    "            \n",
    "            \n",
    "            \n",
    "            network = tf.layers.dense(\n",
    "                inputs=network,\n",
    "                units=num_units,\n",
    "                use_bias=False,\n",
    "                kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                name=\"layer\")\n",
    "\n",
    "            \n",
    "            print network\n",
    "            print \"W:\", network.shape\n",
    "            \n",
    "            self.layers.append(network)\n",
    "\n",
    "            if nonlinearity.__name__ == 'selu':\n",
    "                network = AlphaDropoutLayer(\n",
    "                    incoming=network,\n",
    "                    name=\"{}_alphadropout_{}\".format(self.name, i))\n",
    "            else:\n",
    "                network = lasagne.layers.DropoutLayer(\n",
    "                    incoming=network,\n",
    "                    p=prob_dropout,\n",
    "                    name=\"{}_dropout_{}\".format(self.name, i)\n",
    "                )\n",
    "\n",
    "            self.layers.append(network)\n",
    "            print('\\t\\t{}'.format(lasagne.layers.get_output_shape(network)))\n",
    "        return network\n",
    "\n",
    "    def create_conv_network(self, filters, filter_size, stride,\n",
    "                            pool_mode, pool_stride, nonlinearity):\n",
    "        \n",
    "        conv_dim = len(filter_size[0])\n",
    "        lasagne_pools = ['max', 'average_inc_pad', 'average_exc_pad']\n",
    "        if not all(len(f) == conv_dim for f in filter_size):\n",
    "            raise ValueError('Each tuple in filter_size {} must have a '\n",
    "                             'length of {}'.format(filter_size, conv_dim))\n",
    "        if not all(len(s) == conv_dim for s in stride):\n",
    "            raise ValueError('Each tuple in stride {} must have a '\n",
    "                             'length of {}'.format(stride, conv_dim))\n",
    "        if not all(len(p) == conv_dim for p in pool_stride):\n",
    "            raise ValueError('Each tuple in pool_stride {} must have a '\n",
    "                             'length of {}'.format(pool_stride, conv_dim))\n",
    "        if pool_mode not in lasagne_pools:\n",
    "            raise ValueError('{} pooling does not exist. '\n",
    "                             'Please use one of: {}'.format(pool_mode, lasagne_pools))\n",
    "\n",
    "        print(\"Creating {} Network...\".format(self.name))\n",
    "        if self.input_network is None:\n",
    "            print('\\tInput Layer:')\n",
    "            network = lasagne.layers.InputLayer(shape=self.input_dimensions,\n",
    "                                                input_var=self.input_var,\n",
    "                                                name=\"{}_input\".format(\n",
    "                                                    self.name))\n",
    "            print('\\t\\t{}'.format(lasagne.layers.get_output_shape(network)))\n",
    "            self.layers.append(network)\n",
    "        else:\n",
    "            network = self.input_network['network']. \\\n",
    "                layers[self.input_network['layer']]\n",
    "\n",
    "            print('Appending layer {} from {} to {}'.format(\n",
    "                self.input_network['layer'],\n",
    "                self.input_network['network'].name,\n",
    "                self.name))\n",
    "\n",
    "        if conv_dim == 1:\n",
    "            conv_layer = lasagne.layers.Conv1DLayer\n",
    "            pool = lasagne.layers.Pool1DLayer\n",
    "        elif conv_dim == 2:\n",
    "            conv_layer = lasagne.layers.Conv2DLayer\n",
    "            pool = lasagne.layers.Pool2DLayer\n",
    "        elif conv_dim == 3:\n",
    "            conv_layer = lasagne.layers.Conv3DLayer\n",
    "            pool = lasagne.layers.Pool3DLayer\n",
    "        else:\n",
    "            pool = None   # Linter is stupid\n",
    "            conv_layer = None\n",
    "            ValueError(\"Convolution is only supported for one of the first three dimensions\")\n",
    "\n",
    "        print('\\tHidden Layer:')\n",
    "        for i, (f, f_size, s, p_s) in enumerate(zip(filters,\n",
    "                                                    filter_size,\n",
    "                                                    stride,\n",
    "                                                    pool_stride)):\n",
    "            network = conv_layer(\n",
    "                incoming=network,\n",
    "                num_filters=f,\n",
    "                filter_size=f_size,\n",
    "                stride=s,\n",
    "                pad='same',\n",
    "                nonlinearity=nonlinearity,\n",
    "                name=\"{}_conv{}D_{}\".format(\n",
    "                    self.name, conv_dim, i)\n",
    "            )\n",
    "            network.add_param(\n",
    "                network.W,\n",
    "                network.W.get_value().shape,\n",
    "                **{self.name: True}\n",
    "            )\n",
    "            network.add_param(\n",
    "                network.b,\n",
    "                network.b.get_value().shape,\n",
    "                **{self.name: True}\n",
    "            )\n",
    "            self.layers.append(network)\n",
    "            print('\\t\\t{}'.format(lasagne.layers.get_output_shape(network)))\n",
    "            network = pool(\n",
    "                incoming=network,\n",
    "                pool_size=p_s,\n",
    "                mode=pool_mode,\n",
    "                name=\"{}_{}pool\".format(\n",
    "                    self.name, pool_mode)\n",
    "            )\n",
    "            self.layers.append(network)\n",
    "            print('\\t\\t{}'.format(lasagne.layers.get_output_shape(network)))\n",
    "        return network\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    def create_classification_layer(self, network, num_classes,\n",
    "                                    nonlinearity):\n",
    "        \n",
    "        print('\\tOutput Layer:')\n",
    "        network = lasagne.layers.DenseLayer(\n",
    "            incoming=network,\n",
    "            num_units=num_classes,\n",
    "            nonlinearity=nonlinearity,\n",
    "            name=\"{}_softmax\".format(self.name)\n",
    "        )\n",
    "        network.add_param(\n",
    "            network.W,\n",
    "            network.W.get_value().shape,\n",
    "            **{self.name: True}\n",
    "        )\n",
    "        network.add_param(\n",
    "            network.b,\n",
    "            network.b.get_value().shape,\n",
    "            **{self.name: True}\n",
    "        )\n",
    "        print('\\t\\t{}'.format(lasagne.layers.get_output_shape(network)))\n",
    "        self.layers.append(network)\n",
    "        return network\n",
    "\n",
    "    def cross_entropy_loss(self, prediction, y):\n",
    "        \"\"\"Generate a cross entropy loss function.\"\"\"\n",
    "        print(\"Using categorical cross entropy loss\")\n",
    "        return lasagne.objectives.categorical_crossentropy(prediction,\n",
    "                                                           y).mean()\n",
    "\n",
    "    def mse_loss(self, prediction, y):\n",
    "        \"\"\"Generate mean squared error loss function.\"\"\"\n",
    "        print(\"Using Mean Squared error loss\")\n",
    "        return lasagne.objectives.squared_error(prediction, y).mean()\n",
    "\n",
    "    def create_trainer(self):\n",
    "        \n",
    "        print(\"Creating {} Trainer...\".format(self.name))\n",
    "        # get network output\n",
    "        out = lasagne.layers.get_output(self.network)\n",
    "        # get all trainable parameters from network\n",
    "\n",
    "        self.params = lasagne.layers.get_all_params(\n",
    "            self.network,\n",
    "            trainable=True,\n",
    "            **{self.name: True}\n",
    "        )\n",
    "        if self.input_params is not None:\n",
    "            self.params = self.input_params + self.params\n",
    "\n",
    "        # calculate a loss function which has to be a scalar\n",
    "        if self.cost is None:\n",
    "            if self.num_classes is None or self.num_classes == 0:\n",
    "                self.cost = self.mse_loss(out, self.y)\n",
    "            else:\n",
    "                self.cost = self.cross_entropy_loss(out, self.y)\n",
    "\n",
    "        # calculate updates using ADAM optimization gradient descent\n",
    "        learning_rate_var = T.scalar(name='learning_rate')\n",
    "        if self.optimizer == 'adam':\n",
    "            updates = optimizers[self.optimizer](\n",
    "                loss_or_grads=self.cost,\n",
    "                params=self.params,\n",
    "                learning_rate=learning_rate_var,\n",
    "                beta1=0.9,\n",
    "                beta2=0.999,\n",
    "                epsilon=1e-08\n",
    "            )\n",
    "        elif self.optimizer == 'sgd':\n",
    "            updates = optimizers[self.optimizer](\n",
    "                loss_or_grads=self.cost,\n",
    "                params=self.params,\n",
    "                learning_rate=learning_rate_var\n",
    "            )\n",
    "        else:\n",
    "            updates = None\n",
    "            ValueError(\"No optimizer found\")\n",
    "\n",
    "        # omitted (, allow_input_downcast=True)\n",
    "        return theano.function(\n",
    "            [i for i in [self.input_var, self.y, learning_rate_var] if i],\n",
    "            updates=updates\n",
    "        )\n",
    "\n",
    "    def create_validator(self):\n",
    "        \n",
    "        print(\"Creating {} Validator...\".format(self.name))\n",
    "        # create prediction\n",
    "        val_prediction = lasagne.layers.get_output(\n",
    "            self.network,\n",
    "            deterministic=True\n",
    "        )\n",
    "        # check how much error in prediction\n",
    "        if self.val_cost is None:\n",
    "            if self.num_classes is None or self.num_classes == 0:\n",
    "                self.val_cost = self.mse_loss(val_prediction, self.y)\n",
    "                val_acc = T.constant(0)\n",
    "            else:\n",
    "                self.val_cost = self.cross_entropy_loss(val_prediction, self.y)\n",
    "                # check the accuracy of the prediction\n",
    "                if self.num_classes > 1:\n",
    "                    val_acc = T.mean(T.eq(T.argmax(val_prediction, axis=1),\n",
    "                                          T.argmax(self.y, axis=1)),\n",
    "                                     dtype=theano.config.floatX)\n",
    "                elif self.num_classes == 1:\n",
    "                    val_acc = T.mean(T.eq(T.round(val_prediction,\n",
    "                                                  mode='half_away_from_zero'),\n",
    "                                          self.y),\n",
    "                                     dtype=theano.config.floatX)\n",
    "\n",
    "        return theano.function([self.input_var, self.y],\n",
    "                               [self.val_cost, val_acc])\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    def train(self, epochs, train_x, train_y, val_x, val_y,\n",
    "              batch_ratio=0.1, plot=True, change_rate=None):\n",
    "        \n",
    "        print('\\nTraining {} in progress...\\n'.format(self.name))\n",
    "\n",
    "        if batch_ratio > 1:\n",
    "            batch_ratio = 1\n",
    "        batch_ratio = float(batch_ratio)\n",
    "\n",
    "        self.record = dict(\n",
    "            epoch=[],\n",
    "            train_error=[],\n",
    "            train_accuracy=[],\n",
    "            validation_error=[],\n",
    "            validation_accuracy=[]\n",
    "        )\n",
    "\n",
    "        if self.stopping_rule == 'best_validation_error':\n",
    "            best_state = None\n",
    "            best_epoch = None\n",
    "            best_error = float('inf')\n",
    "\n",
    "        elif self.stopping_rule == 'best_validation_accuracy':\n",
    "            best_state = None\n",
    "            best_epoch = None\n",
    "            best_accuracy = 0.0\n",
    "\n",
    "        output_shape = lasagne.layers.get_output_shape(self.network)\n",
    "        if output_shape[1:] != train_y.shape[1:]:\n",
    "            raise ValueError(\n",
    "                'Shape mismatch: non-batch dimensions don\\'t match.'\n",
    "                '\\n\\tNetwork output shape: {}'\n",
    "                '\\n\\tLabel shape (train_y): {}'.format(\n",
    "                    output_shape,\n",
    "                    train_y.shape))\n",
    "\n",
    "        if train_x.shape[0] * batch_ratio < 1.0:\n",
    "            batch_ratio = 1.0 / train_x.shape[0]\n",
    "            print('Warning: Batch ratio too small. Changing to {:.5f}'.format(batch_ratio))\n",
    "        try:\n",
    "\n",
    "            for epoch in range(epochs):\n",
    "                epoch_time = time.time()\n",
    "                print(\"--> Epoch: {}/{}\".format(\n",
    "                    epoch,\n",
    "                    epochs - 1\n",
    "                ))\n",
    "\n",
    "                train_x, train_y = shuffle(train_x, train_y, random_state=0)\n",
    "\n",
    "                for i in range(int(1 / batch_ratio)):\n",
    "                    size = train_x.shape[0]\n",
    "                    b_x = train_x[int(size * (i * batch_ratio)):\n",
    "                                  int(size * ((i + 1) * batch_ratio))]\n",
    "                    b_y = train_y[int(size * (i * batch_ratio)):\n",
    "                                  int(size * ((i + 1) * batch_ratio))]\n",
    "\n",
    "                    self.trainer(b_x, b_y, self.learning_rate)\n",
    "\n",
    "                    sys.stdout.flush()\n",
    "                    sys.stdout.write('\\r\\tDone {:.1f}% of the epoch'.format\n",
    "                                     (100 * (i + 1) * batch_ratio))\n",
    "\n",
    "                    if change_rate is not None:\n",
    "                        if not callable(change_rate):\n",
    "                            raise ValueError(\n",
    "                                'Parameter change_rate must be a function '\n",
    "                                'that returns a new learning rate. '\n",
    "                                'Learning rate remains unchanged.'\n",
    "                            )\n",
    "                        # print('Modifying learning rate from {}'.format(\n",
    "                        #     self.learning_rate)\n",
    "                        # ),\n",
    "                        self.learning_rate = change_rate(\n",
    "                            self.init_learning_rate,\n",
    "                            self.minibatch_iteration\n",
    "                        )\n",
    "                        # print('to {}'.format(self.learning_rate))\n",
    "                    self.minibatch_iteration += 1\n",
    "\n",
    "                train_error, train_accuracy = self.validator(train_x, train_y)\n",
    "                validation_error, validation_accuracy = self.validator(val_x,\n",
    "                                                                       val_y)\n",
    "\n",
    "                if self.stopping_rule == 'best_validation_error' and validation_error < best_error:\n",
    "                    best_epoch = epoch\n",
    "                    best_error = validation_error\n",
    "\n",
    "                elif self.stopping_rule == 'best_validation_accuracy' and validation_accuracy > best_accuracy:\n",
    "                    best_epoch = epoch\n",
    "                    best_accuracy = validation_accuracy\n",
    "\n",
    "                self.record['epoch'].append(epoch)\n",
    "                self.record['train_error'].append(train_error)\n",
    "                self.record['train_accuracy'].append(train_accuracy)\n",
    "                self.record['validation_error'].append(validation_error)\n",
    "                self.record['validation_accuracy'].append(validation_accuracy)\n",
    "                epoch_time_spent = time.time() - epoch_time\n",
    "                print(\"\\n\\ttrain error: {:.6f} |\"\" train accuracy: {:.6f} in {:.2f}s\".format(\n",
    "                    float(train_error),\n",
    "                    float(train_accuracy),\n",
    "                    epoch_time_spent))\n",
    "                print(\"\\tvalid error: {:.6f} | valid accuracy: {:.6f} in {:.2f}s\".format(\n",
    "                    float(validation_error),\n",
    "                    float(validation_accuracy),\n",
    "                    epoch_time_spent))\n",
    "\n",
    "                eta = epoch_time_spent * (epochs - epoch - 1)\n",
    "                minute, second = divmod(eta, 60)\n",
    "                hour, minute = divmod(minute, 60)\n",
    "                print(\"\\tEstimated time left: {}:{}:{} (h:m:s)\\n\".format(\n",
    "                    int(hour),\n",
    "                    int(minute),\n",
    "                    int(second)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\n\\n**********Training stopped prematurely.**********\\n\\n\")\n",
    "        finally:\n",
    "            self.timestamp = get_timestamp()\n",
    "\n",
    "            if self.stopping_rule == 'best_validation_error':\n",
    "                print(\"STOPPING RULE: Rewinding to epoch {} which had the lowest validation error: {}\\n\".format(best_epoch, best_error))\n",
    "                \n",
    "\n",
    "            elif self.stopping_rule == 'best_validation_accuracy':\n",
    "                print(\"STOPPING RULE: Rewinding to epoch {} which had the highest validation accuracy: {}\\n\".format(best_epoch, best_accuracy))\n",
    "                \n",
    "        \n",
    "    def forward_pass(self, input_data, convert_to_class=False):\n",
    "        \n",
    "        if convert_to_class:\n",
    "            return get_class(self.output(input_data))\n",
    "        else:\n",
    "            return self.output(input_data)\n",
    "\n",
    "    @classmethod\n",
    "    def load_model(cls, load_path):\n",
    "       \n",
    "        print('Loading model from: {}'.format(load_path))\n",
    "        with open(load_path, 'rb') as f:\n",
    "            instance = pickle.load(f)\n",
    "        return instance\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data folder already exists\n",
      "Loading training images...\n",
      "Loading training labels...\n",
      "Loading testing images...\n",
      "Loading testing labels...\n"
     ]
    }
   ],
   "source": [
    "(train_images, train_labels, test_images, test_labels) = mnist_loader.load_fashion_mnist()\n",
    "\n",
    "train_labels = get_one_hot(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_dense_config = {\n",
    "    'mode': 'dense',\n",
    "    'units': [512, 100],\n",
    "    'dropouts': [0.2, 0.3],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating 3_dense_test Network...\n",
      "\tInput Layer:\n",
      "\t\t(?, 784)\n",
      "\tHidden Layer:\n",
      "Tensor(\"layer/MatMul:0\", shape=(?, 512), dtype=float32)\n",
      "W: (?, 512)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'output_shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-9cbf8633b521>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'rectify'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mpred_activation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'softmax'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     optimizer='adam')\n\u001b[0m",
      "\u001b[1;32m<ipython-input-20-f14a7ed12e75>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, dimensions, input_var, y, config, input_network, num_classes, activation, pred_activation, optimizer, stopping_rule, learning_rate)\u001b[0m\n\u001b[0;32m     58\u001b[0m         self.network = self.build_model(\n\u001b[0;32m     59\u001b[0m             \u001b[0mconfig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m             \u001b[0mnonlinearity\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mactivations\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m         )\n\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-20-f14a7ed12e75>\u001b[0m in \u001b[0;36mbuild_model\u001b[1;34m(self, config, nonlinearity)\u001b[0m\n\u001b[0;32m     87\u001b[0m                 \u001b[0munits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'units'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m                 \u001b[0mdropouts\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'dropouts'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m                 \u001b[0mnonlinearity\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnonlinearity\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m             )\n\u001b[0;32m     91\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'conv'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-20-f14a7ed12e75>\u001b[0m in \u001b[0;36mcreate_dense_network\u001b[1;34m(self, units, dropouts, nonlinearity)\u001b[0m\n\u001b[0;32m    183\u001b[0m                     \u001b[0mincoming\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m                     \u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprob_dropout\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 185\u001b[1;33m                     \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"{}_dropout_{}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m                 )\n\u001b[0;32m    187\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\Anaconda2\\lib\\site-packages\\lasagne\\layers\\noise.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, incoming, p, rescale, shared_axes, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m     def __init__(self, incoming, p=0.5, rescale=True, shared_axes=(),\n\u001b[0;32m     72\u001b[0m                  **kwargs):\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDropoutLayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mincoming\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_srng\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomStreams\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_rng\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2147462579\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\Anaconda2\\lib\\site-packages\\lasagne\\layers\\base.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, incoming, name)\u001b[0m\n\u001b[0;32m     35\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_layer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mincoming\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput_shape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_layer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mincoming\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'output_shape'"
     ]
    }
   ],
   "source": [
    "import tf_utils\n",
    "with tf.Graph().as_default():\n",
    "    input_var, y = tf_utils.init_placeholders(len(train_images[0]), len(train_labels[0]))\n",
    "    \n",
    "    dense_net = Network(\n",
    "    name='3_dense_test',\n",
    "    dimensions=[None] + list(train_images.shape[1:]),\n",
    "    input_var=input_var,\n",
    "    y=y,\n",
    "    config=network_dense_config,\n",
    "    input_network=None,\n",
    "    num_classes=10,\n",
    "    activation='rectify',\n",
    "    pred_activation='softmax',\n",
    "    optimizer='adam')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Use to load model from disk\n",
    "# # dense_net = Network.load_model('models/20170704194033_3_dense_test.network')\n",
    "dense_net.train(\n",
    "    epochs=2,\n",
    "    train_x=train_images[:50000],\n",
    "    train_y=train_labels[:50000],\n",
    "    val_x=train_images[50000:60000],\n",
    "    val_y=train_labels[50000:60000],\n",
    "    batch_ratio=0.05,\n",
    "    plot=True\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = tf.keras.layers.InputLayer(input_shape = [None] + list(train_images.shape[1:]), input_tensor=input_var, name='input_layer').output\n",
    "print l1.shape\n",
    "l2 = tf.layers.dense(\n",
    "      inputs=l1,\n",
    "      units = 50)\n",
    "print l2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.layers.InputLayer(input_tensor=input_var, name='input_layer').output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_tf = data_tf.test.images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_labels_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_var = T.fmatrix('input')\n",
    "print input_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_var.get_shape().as_list()[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.glorot_uniform_initializer () "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = tf.Variable([], name=\"v1\")\n",
    "v1.initializer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1.initial_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_variable = tf.get_variable(\"my_variable\", [1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = tf.get_variable(\"weights\", [784, 512])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_network(units, n_layers, filter_width):\n",
    "        \"\"\"Assemble Convolutional neural network\n",
    "\n",
    "        Args:\n",
    "            units: input units to be convolved with kernels\n",
    "            n_layers: number of layers\n",
    "            filter_width: width of the filter (kernel)\n",
    "\n",
    "        Returns:\n",
    "            units: output units of the CNN\n",
    "            auxiliary_outputs: auxiliary outputs from every layer\n",
    "        \"\"\"\n",
    "        n_filters = units.get_shape().as_list()[-1]\n",
    "        auxiliary_outputs = []\n",
    "        for n_layer in range(n_layers):\n",
    "            units = tf.layers.conv1d(units,\n",
    "                                     n_filters,\n",
    "                                     filter_width,\n",
    "                                     padding='same',\n",
    "                                     name='Layer_' + str(n_layer),\n",
    "                                     activation=None,\n",
    "                                     kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "            auxiliary_outputs.append(units)\n",
    "            units = tf.nn.relu(units)\n",
    "        return units, auxiliary_outputs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_network(input_var, 20, (5,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
